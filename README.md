# Video Prediction Project for Weizmann Data

This repository contains the code required to 1) download Weizmann data, 2) train three different deep learning architectures on the data, and 3) plot the frames generated by the trained models.

![Example of a 10-frame video sequence](https://github.com/iProov/predict-weizmann-video/plots/sample_plot.png)


## Downloading data
Weizmann data can be download using the shell scripts provided. First run `./data/download_weizmann.sh`, which downloads a .zip file. Next, run `./data/extract_weizmann.sh`, which extracts files from the .zip file and deletes the .zip file. 

Once the video files are downloaded, use the *./data/vid_to_np.ipynb* script to read the video files and save them as numpy arrays. The script contains code to extract 10-frame sequences from the videos which have around 100-200 frames. For the jumping jack videos, it is best to use 1 every 3 frame (for e.g., we form a 10-frame sequence with frames [1, 4, 7, 10, 13, 16, 19, 22, 25, 28]), to have a small but non-trivial movement in the arms and legs between every frame. The script saves the extracted 10-frame sequences as a numpy array.

This next step is optional. You can augment the data by using the notebook found at *./data/augment_data.ipynb*. For my thesis, I used a horizontal flip augmentation technique, and you can modify that or add on to it in the notebook. This notebook will then save the augmented data as another numpy array.


## Training
The python scripts prefixed with *train_* are for training the various models. The architectures are implemented in Pytorch and can be found in *./models/*. The hyperparameters for training can be defined in those scripts. For example, in your favourite environment (i.e. conda, Docker), you can run 
```python train_predrnn.py```
to train a PredRNN model. Metrics are automatically logged with a Tensorboard logger.

## Plotting
The Tensorboard logger already contains a sample plot of the predicted frames. If you wish to make further plots, you can use the *plot_5to5_plot1.ipynb*
 notebook to do so. You will need to modify the checkpoint path to load the trained paramaters and weights.